# XGBoost on Mushroom Classification

## 📖 Description

This project uses XGBoost to predict whether mushrooms are edible or poisonous based on categorical features.

## 🧠 Model Explanation

Boosting is an ensemble learning technique used to create a strong model by combining many weak models (usually decision trees). A weak model is one that performs just slightly better than random guessing.

 Popular Boosting Algorithms:

AdaBoost (Adaptive Boosting)

Gradient Boosting

XGBoost (Extreme Gradient Boosting) — fast and powerful

LightGBM — very efficient for large datasets

CatBoost — works well with categorical features

## ✅ Benefits

High accuracy

Built-in handling of missing values

Fast and scalable

## ⚠️ Limitations

More complex to tune

Requires more compute power

## 📊 Dataset

Name: Mushroom Dataset

Source: UCI ML Repository

Features: Cap shape, color, odor, gill type, etc.

Target: Edible or poisonous
